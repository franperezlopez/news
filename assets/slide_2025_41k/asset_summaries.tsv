id	summary
1760293954763.533	**Gemini Enterprise** is Google Cloud‚Äôs advanced platform designed to bring AI capabilities to every employee and workflow across organizations. It enables users to discover, create, share, and run AI agents securely, leveraging Google‚Äôs latest Gemini models. The platform offers instant access to multimodal AI, no-code tools for custom agent building, ready-to-use agents like Deep Research and Coding Agents, and seamless integration with business data sources such as Google Workspace, Microsoft 365, Salesforce, SAP, and BigQuery. Centralized management, robust security, compliance‚Ä¶
1760293954763.3547	Agentic Context Engineering Great paper on agentic context engineering. The recipe: Treat your system prompts and agent memory as a living playbook. Log trajectories, reflect to extract actionable bullets (strategies, tool schemas, failure modes), then merge as append-only deltas with periodic semantic de-dupe. Use execution signals and unit tests as supervision. Start offline to warm up a seed playbook, then continue online to self-improve. On AppWorld, ACE consistently beats strong baselines in both offline and online adaptation. Example: ReAct+ACE (offline)‚Ä¶
1760293954763.695	This article investigates whether using the same large language model (LLM) for both generating agent outputs and evaluating them introduces self-evaluation bias. The authors built a movie recommendation agent utilizing four top LLMs‚ÄîOpenAI GPT-4.1, Anthropic Claude 3.7 Sonnet, Google Gemini 2.5 Flash, and Qwen3-235B‚Äîand compared evaluation results when models judged their own outputs versus those from other models. The evaluation focused on orchestration quality using a strict rubric, and results were benchmarked against human annotations for objectivity. Findings showed that‚Ä¶
1760293954764.7268	The article details how OpenAI used Codex across multiple facets of their 2025 DevDay event, highlighting increased productivity, rapid prototyping, and streamlined development workflows. Codex was instrumental in powering stage demos, building custom applications (like a venue lighting controller and a beat pad), generating video games for arcade cabinets, and rebuilding demo apps by automating code transformation and UI generation. Team members leveraged the Codex CLI, IDE extension, and Codex Cloud to delegate and parallelize tasks, organize documentation, conduct code‚Ä¶
1760293954764.0354	The "Sora 2 Prompting Guide" provides best practices for crafting effective video prompts for OpenAI's Sora 2 generative video model. It emphasizes balancing specificity and creative freedom in prompts, highlighting that detailed instructions yield more consistent results while open-ended prompts encourage creative variation. The guide covers prompt anatomy, including describing scene, camera, lighting, action, and dialogue, and offers tips for controlling visual style, motion, and timing. Using image input as a reference for composition and style is recommended for greater‚Ä¶
1760293954764.2793	I have two modes when I'm prompting LLM's. When I'm building an app containing an LLM, I go pretty hard. I use Anthropic's 10-section template. But for one-off prompts to Claude Code, I go down to 4:
1760293954764.2239	always nice when a big lab does me the kindness of validating my research from a year ago üòòüòò this kind of attack is called ‚ÄúBasilisk Venom‚Äù btw‚Äîget it right! üß™üêâ
1760293954764.6323	Introducing linear scaling of reasoning: ùêìùê°ùêû ùêåùêöùê´ùê§ùê®ùêØùê¢ùêöùêß ùêìùê°ùê¢ùêßùê§ùêûùê´ Reformulate RL so thinking scales ùêé(ùêß) ùêúùê®ùê¶ùê©ùêÆùê≠ùêû, not O(n^2), with O(1) ùê¶ùêûùê¶ùê®ùê´ùê≤, architecture-agnostic. Train R1-1.5B into a markovian thinker with 96K thought budget, ~2X accuracy üßµ https://t.co/72pV3tcER9
1760293954765.561	Live! Try out the compounding engineering philosophy in Claude Code: https://t.co/6LI5u1ZHTh https://t.co/qumUssCrsV
1760299841576.3933	The article discusses the evolution of AI agents from "Shallow Agents" (Agent 1.0) to "Deep Agents" (Agent 2.0). Shallow Agents operate using simple loops within the LLM‚Äôs context window, making them suitable for short, transactional tasks but prone to losing context and failing on complex, multi-step objectives due to overflow and lack of recovery mechanisms. Deep Agents, by contrast, use explicit planning, hierarchical delegation to specialized sub-agents, persistent external memory, and sophisticated context engineering. This architecture enables them to tackle‚Ä¶
1760351035742.4875	The paper introduces "Markovian Thinking" as a new paradigm for training reasoning language models using reinforcement learning (RL). Traditional RL environments for long chain-of-thought (LongCoT) reasoning make the state the entire prompt plus all reasoning tokens so far, causing the context size‚Äîand thus compute and memory costs‚Äîto grow quadratically as the reasoning length increases. Markovian Thinking instead structures reasoning into fixed-size chunks, so the model conditions only on a constant-size state, decoupling the length of reasoning from context size. At‚Ä¶
1760351035743.9263	i installed perplexity comet for one reason: getting an api key for google services (fk their dumb cloud platform, worst ux on earth) IT WORKED ON FIRST TRY??? https://t.co/QrUpk9Ontc
1760351035743.3762	deepmind just dropped a handy little colab on fine-tuning gemma3-270m for emoji generation. this is a super lower resource task with 270m parameter model, qlora, short sequences. so it's a great one to try out locally or on colab. it's also a nice one to deploy in a js app with transformers.js. i'll drop all the resources in thread.
1760351035744.5483	https://t.co/uVpdOIgnIN
1760351035744.1445	Introducing Qwen3-VL Cookbooks! üßë‚Äçüç≥ A curated collection of notebooks showcasing the power of Qwen3-VL‚Äîvia both local deployment and API‚Äîacross diverse multimodal use cases: ‚úÖ Thinking with Images ‚úÖ Computer-Use Agent ‚úÖ Multimodal Coding ‚úÖ Omni Recognition ‚úÖ Advanced Document Parsing ‚úÖ Precise Object Grounding (across formats!) ‚úÖ General OCR & Key Info Extraction ‚úÖ 3D Grounding ‚úÖ Long Document Understanding ‚úÖ Spatial Reasoning ‚úÖ Mobile Agent ‚úÖ Video Understanding üîóLink: https://t.co/6ONowbWDTF ‚öôÔ∏è API: https://t.co/XkK2ubI7Hz üí¨ Qwen Chat: https://t.co/PKOQqHlAj4 Explore, experiment,‚Ä¶
1760351035744.6936	ü™©The one and only @stateofaireport 2025 is live! ü™© It‚Äôs been a monumental 12 months for AI. Our 8th annual report is the most comprehensive it's ever been, covering what you *need* to know about research, industry, politics, safety and our new usage data. My highlight reel:
1760351035745.9578	The **State of AI Report 2025** provides an annual analysis of key developments in artificial intelligence, covering research breakthroughs, industry adoption, politics, safety, and practitioner survey results. This year‚Äôs highlights include OpenAI maintaining a narrow lead at the AI frontier, intense competition from China‚Äôs DeepSeek, Qwen, and Kimi, and significant advances in reasoning capabilities. AI‚Äôs role as a scientific collaborator has grown, with autonomous systems generating and validating hypotheses, and structured reasoning is now influencing embodied AI in the physical‚Ä¶
1760351035745.6172	Claude Code now supports plugins, allowing users to customize their coding environment with slash commands, subagents, MCP servers, and hooks that can be installed or removed with a single command. These plugins make it easy to package and share custom setups for workflows, standards enforcement, tool integration, and productivity enhancements across teams and the wider community. Plugins can be discovered and distributed through marketplaces, which are simple to host using a repository with a properly formatted JSON file. Users can‚Ä¶
1760351035746.19	Claude Code Weekly Round Up This week besides plugins we also shipped MCP server toggling, reduced the system prompt, made faster tool calling and smoother rendering, Ctrl+G to edit prompts in your text editor, and better env variable handling in the permission system.
1760351035746.981	RIP fine-tuning ‚ò†Ô∏è This new Stanford paper just killed it. It‚Äôs called 'Agentic Context Engineering (ACE)' and it proves you can make models smarter without touching a single weight. Instead of retraining, ACE evolves the context itself. The model writes, reflects, and edits its own prompt over and over until it becomes a self-improving system. Think of it like the model keeping a growing notebook of what works. Each failure becomes a strategy. Each success becomes a rule. The results‚Ä¶
1760351035747.1365	Agentic Context Engineering (ACE) is a framework designed to enhance the performance of large language model (LLM) applications by treating input contexts as evolving playbooks. Unlike traditional weight-tuning or static prompt engineering, ACE uses a modular process‚Äîgeneration, reflection, and curation‚Äîto incrementally refine and organize context, preventing the loss of detailed knowledge (context collapse) and mitigating brevity bias. This approach supports both offline (system prompts) and online (agent memory) adaptation, scales effectively with long-context models, and leverages natural execution feedback without‚Ä¶
1760351035747.3743	Microsoft did something interesting here üëÄ ‚ÄúUnlike typical LLMs that are trained to play the role of the "assistant" in conversation, we trained UserLM-8b to simulate the ‚Äúuser‚Äù role in conversation‚Äù https://t.co/mGgWZBvu7o
1760351035748.4438	Google Cloud has announced the launch of **Google Skills**, a new platform that consolidates nearly 3,000 courses and labs from Google Cloud, Google DeepMind, Grow with Google, and Google for Education, aiming to make AI and cloud learning more accessible and engaging. Key updates include hands-on labs powered by Gemini Code Assist, new skill badges for developers, personalized learning features for organizations, and gamified elements like leagues, achievements, and streaks to boost engagement. The platform also maintains free access to‚Ä¶
1760351035748.0127	Introducing @mike64_t's work on "Recurrence-Complete Frame-based Action Models" A paper on why long-horizon perception requires rethinking recurrence. https://t.co/wf8ZXqgcln
1760351035748.1301	It‚Äôs clear next-gen reasoning LLMs will run for millions of tokens. RL at 1M needs ~100√ó compute than 128K. Our Markovian Thinking keeps compute scaling linear instead. Check out Milad‚Äôs thread; some of my perspectives below: https://t.co/MYChqLQGwp
1760351035749.579	A joint study by Anthropic, the UK AI Security Institute, and the Alan Turing Institute found that large language models (LLMs) of any size can be "backdoored" with as few as 250 poisoned documents, regardless of total training data volume or model scale. Contrary to previous assumptions that attackers needed to control a percentage of training data, the research demonstrates that a small, fixed number of malicious samples is sufficient to induce vulnerabilities such as denial-of-service behaviors (e.g., making the‚Ä¶
1760351035749.5247	Today we introduced Gemini Enterprise, built with our most advanced Gemini models. It allows you to chat with your company‚Äôs documents, data and apps as well as build and deploy AI agents, all grounded in your information and context. Have a look at how it helps you build an agent for almost anything:
1760351035750.4229	Google's Gemma 3 270M is a lightweight, open-source language model designed for easy customization and on-device deployment. This blog post demonstrates how to fine-tune Gemma 3 270M for a task‚Äîspecifically, translating text into emojis‚Äîusing a simple dataset and efficient techniques like QLoRA, which reduces memory requirements and allows fine-tuning on free GPU resources such as Google Colab. After fine-tuning, the model can be quantized to further reduce its size (to under 300MB), making it suitable for fast, private, and offline‚Ä¶
1760351035750.6382	The article introduces the new `make_judge` API in MLflow 3.4, which enables users to create custom, domain-specific LLM evaluation scorers (judges) using simple declarative instructions. This approach allows for rapid development of evaluators that can assess GenAI application outputs based on nuanced, expert-driven criteria‚Äîsuch as empathy in customer support bots or accuracy in code generation‚Äîwithout extensive prompt engineering or complex logic. These scorers can analyze both simple responses and complex agent traces, leveraging built-in tools for process introspection and evidence-based‚Ä¶
1760351035750.1243	The blog post announces the general availability of Weaviate's Query Agent with a new feature called **Search Mode**, designed to deliver highly accurate information retrieval by integrating advanced IR techniques such as query expansion, decomposition, schema introspection, and reranking. The authors benchmark Search Mode against Weaviate's standard Hybrid Search (which combines vector search and BM25 with Snowflake Arctic 2.0 embeddings using Reciprocal Rank Fusion) across 12 industry-standard IR datasets, including BEIR, LoTTe, BRIGHT, EnronQA, and WixQA, using metrics like Success@K,‚Ä¶
1760351035751.8296	Google DeepMind has introduced AlphaEarth Foundations, a new AI model that integrates petabytes of Earth observation data‚Äîsuch as optical satellite images, radar, and climate simulations‚Äîto generate a unified digital representation of the planet‚Äôs terrestrial land and coastal waters. This model functions like a virtual satellite, offering scientists consistent, detailed, and compact summaries of the world‚Äôs land in 10x10 meter squares. Its key innovation is producing highly efficient data embeddings, which require much less storage and enable rapid, accurate, and large-scale‚Ä¶
1760351035751.5054	AlphaEarth Foundations is a new state-of-the-art model that revolutionizes global mapping and monitoring. This work already powers partners around the world to address challenges from deforestation to urban expansion. https://t.co/7PVLGUHcxR
1760351035752.4214	Maximize Droid's performance in your development workflow by leveraging four key features: the Factory IDE plugin for real-time context awareness, Spec Mode for thorough exploration and planning before coding, AGENTS.md to capture and enforce your coding standards, and agent readiness through automated verification tools like linters and tests. These features work together to reduce unnecessary tool calls, improve first-time code quality, maintain consistent standards, and enable self-correcting code by integrating with your existing CI/CD tools. To get started, install the‚Ä¶
1760351035752.39	MLflow 3.4 introduces make_judge, a declarative API for building domain-specific LLM judges that automatically align with expert preferences. This approach removes complex prompt engineering, enables agentic scorers with built-in trace introspection, and delivers meaningful reductions in evaluation errors based on task and feedback quality. Automate building domain-specific evaluators with MLflow üîó Dive in: https://t.co/3qWe6wug7Z #opensource #genai #oss #llm #judges
1760351035754.3926	From the team tracking human forecasting abilities for years: Current models already beat most humans and ‚ÄúA linear extrapolation of state-of-the-art LLM forecasting performance suggests LLMs will match superforecasters in November 2026.‚Äù
1760351035755.3909	I took a look at the paper. And as incredibly impressive as this research is, many see it as confirmation that SLMs can achieve extremely high performance. But the comparison is very skewed. Why? The Tiny Recursive Model (TRM) is an extremely small, recursive computing model (only ~7 M parameters, 2 layers) that, in puzzle benchmarks such as Sudoku Extreme, Maze Hard, and ARC-AGI, sometimes generalizes better than much larger LLMs, even though it is trained with only a few‚Ä¶
1760351035756.1553	From the Hierarchical Reasoning Model (HRM) to a new Tiny Recursive Model (TRM). A few months ago, the HRM made big waves in the AI research community as it showed really good performance on the ARC challenge despite its small 27M size. (That's about 22x smaller than the smallest Qwen3 0.6B model.) Now, the new "Less is More: Recursive Reasoning with Tiny Networks" paper proposes Tiny Recursive Model (TRM), which a simpler and even smaller model (7M, 4√ó smaller than‚Ä¶
1760351035756.7368	This blog post details the process of building a Byte Pair Encoding (BPE) tokenizer from scratch, emphasizing efficiency and sample effectiveness over off-the-shelf solutions. The author explains the fundamentals of BPE, including byte-level tokenization, frequency-based pair merging, and the importance of pre-tokenization using advanced regex patterns for better handling of numbers, contractions, and punctuation. Practical optimizations are discussed, such as caching frequency counts and using partial sorting to speed up training, as well as employing Rust for computationally intensive pre-tokenization‚Ä¶
1760351035757.4158	Absolutely don‚Äôt do this
1760351035757.6836	The main content is a browsable directory of Gemini CLI extensions, which enable integration of the Gemini AI-powered command line with a wide variety of third-party tools, platforms, and services. These extensions support functionalities such as code review, security scanning, database management, cloud services deployment, observability, and workflow automation across popular ecosystems including Google Cloud, Terraform, Stripe, Grafana, Neo4j, Redis, Postman, Shopify, and many more. Each extension entry lists its name, repository link, version, brief description, and tags indicating supported‚Ä¶
1760351035758.2927	Google has launched an extension marketplace for Gemini CLI. Over 70 extensions are already available. https://t.co/KfcMSJ4WIH
1760351035758.4365	Introducing Grok Imagine v0.9, our new video generation model with massive upgrades from v0.1 in visual quality, motion, audio generation, and more. Try it for free in the Grok App.
1760351035759.5432	Pydantic version 2.12.0 is out! üéâ This release provides support for Python 3.14 and deferred annotations! https://t.co/lmIVSTCBwY
1760351035759.1821	You can now vibe code in Google AI Studio using your voice, unlocking a new paradigm we are calling "yap-to-app", enjoy : ) https://t.co/omvrIAZkpy
1760351035760.7842	The article "Not all bits are made equal" by Shashwat Goel argues that not all pieces of information have equal importance; higher-order bits‚Äîthose that most dramatically affect outcomes‚Äîmatter exponentially more than lower-order bits. Using examples from estimating large numbers and decision-making in research, Goel emphasizes prioritizing the most critical questions, referencing Richard Hamming‚Äôs advice to focus on important problems for impactful work. In the context of AI, Goel contrasts Supervised Finetuning (SFT), which values every bit equally, with Reinforcement Learning‚Ä¶
1760351035761.7021	‚ú® We're proud to release the ColBERT Nano series of models. All 3 of these models come in at less than 1 million parameters (250K, 450K, 950K)! Late interaction models perform shockingly well with small models. Collection: https://t.co/gSVLMUrWcf Model: https://t.co/wUDXXDFRv7 https://t.co/6TR7PCEIxn
1760351035761.305	My brain broke when I read this paper. A tiny 7 Million parameter model just beat DeepSeek-R1, Gemini 2.5 pro, and o3-mini at reasoning on both ARG-AGI 1 and ARC-AGI 2. It's called Tiny Recursive Model (TRM) from Samsung. How can a model 10,000x smaller be smarter? Here's how it works: 1. Draft an Initial Answer: Unlike an LLM that writes word-by-word, TRM first generates a quick, complete "draft" of the solution. Think of this as its first rough guess.‚Ä¶
1760351035762.732	Python 3.14 has been released, introducing major features such as template strings (t-strings) for enhanced string interpolation and introspection, official support for the free-threaded (no-GIL) build of the interpreter, and performance improvements for versions built with Clang. The update also brings new syntax warnings for control-flow statements in `finally` clauses, further deprecates `typing.ByteString`, and enhances the REPL with syntax highlighting and import autocompletion. Users are encouraged to upgrade their Python tooling, including Ruff and uv, to take advantage of Python‚Ä¶
1760351035762.1748	Love this use of the term "brain coding" to describe good old-fashioned programming using your brain - quoting Thomas Klausner https://t.co/vs8L44HCdw
1760351035762.255	OpenAI relies on PostgreSQL as the backbone of its most critical systems, leveraging Azure Database for PostgreSQL to support massive growth and demand for services like ChatGPT. Initially, OpenAI deployed a straightforward primary-replica architecture focused on read scalability, but as usage surged, write operations became a bottleneck. To overcome these challenges, the team reduced unnecessary writes, optimized slow queries, used connection pooling, and enforced strict schema governance. These strategies enabled OpenAI to achieve high throughput, global low-latency reads, and improved‚Ä¶
1760351035763.5347	new in the build tab: vibe code with your voice dictate changes, add features, or describe your app with our new speech-to-text feature it intelligently removes filler words and mistakes for a clean prompt every time ‚¨áÔ∏è https://t.co/pr2m3JNe9G
1760351035763.5044	The problem with codex high is that gpt5 as a model series is quite small, and quality degrades significantly as it fills the context window with tool calls and reasoning tokens. High reasoning means the model doesn‚Äôt start solving your problem until it‚Äôs consumed potentially more than half of the context window. If the problem‚Äôs scope is large it then may not be able to complete the task before compaction, and even if it isn‚Äôt, it might overthink and produce‚Ä¶
1760351035764.3574	BIG NEWS: We‚Äôre shipping AI Mode to new markets &amp; languages, including Europe. This brings AI Mode to 200+ markets &amp; 40+ languages total! This is a huge moment for AI in Search, and I couldn't be more excited for millions more people to experience it! üöÄüöÄüöÄ https://t.co/9hJka0oNpa
1760351035764.034	Google did it again! First, they launched ADK, a fully open-source framework to build, orchestrate, evaluate, and deploy production-grade Agentic systems. And now, they have made it even powerful! Google ADK is now fully compatible with all three major AI protocols out there: - MCP: To connect to external tools - A2A: To connect to other agents - AG-UI: To connect to users. AG-UI is the newest addition, which is an open-source protocol that enables agents to collaborate with users.‚Ä¶
1760351035765.0535	Crazy paper from Google DeepMind Dreamer 4 can mine Minecraft diamonds without ever touching the real game It trained entirely inside its own world model, kinda like an ‚Äúimaginary world‚Äù, showing agents can tackle long horizon tasks safely by just learning from videos! https://t.co/5cG9oYyt51
1760351035766.8892	Python 3.14 has been officially released, introducing major new features such as template string literals, deferred evaluation of annotations, and support for subinterpreters, which enable better multi-core usage despite the GIL. Additional improvements include enhanced asyncio introspection, Zstandard compression via a new module, REPL syntax highlighting, and numerous library updates. Free-threaded Python builds are now supported for those wanting to bypass the GIL entirely, provided their dependencies are compatible. With Python 3.14's arrival, Python 3.9 has reached end-of-life, allowing developers‚Ä¶
1760351035766.2764	I think we are all in agreement that it is literally impossible for a &lt;10M model to be more useful or intelligent than Gemini 2.5 Pro or o3 mini. Therefore, any benchmark which allows for a 10M model to come out on top is useless and not worth anyone‚Äôs time.
1760351035767.732	Starting today, you can use any open-source model to power your Droids. Droids achieve the highest scores across all open-source models on Terminal-Bench. We find GLM 4.6 to be the most performant, remarkably achieving a score in Droid that beats Sonnet 4 in Claude Code. https://t.co/IPsG9adF4P
1760351035767.6853	Reinforcement Learning (RL) has long been the dominant method for fine-tuning, powering many state-of-the-art LLMs. Methods like PPO and GRPO explore in action space. But can we instead explore directly in parameter space? YES we can. We propose a scalable framework for full-parameter fine-tuning using Evolution Strategies (ES). By skipping gradients and optimizing directly in parameter space, ES achieves more accurate, efficient, and stable fine-tuning. Paper: https://t.co/Es44ZqfcJ6 Code: https://t.co/eduztHwrLS
1760351035768.7747	This paper introduces a scalable approach to fine-tuning large language models (LLMs) using Evolution Strategies (ES), positioning ES as a viable alternative to the currently dominant Reinforcement Learning (RL) methods. The authors demonstrate that ES can efficiently search over billions of parameters, outperforming RL in several key aspects: sample efficiency, robustness across different base LLMs, stability of performance, reduced reward hacking, and better tolerance to long-horizon rewards. The work addresses several limitations of RL-based fine-tuning, such as low sample efficiency,‚Ä¶
1760351035768.097	Google Research has introduced Speech-to-Retrieval (S2R), a new voice search technology that bypasses traditional automatic speech recognition (ASR) by mapping spoken queries directly to search intent, rather than first converting speech to text. This dual-encoder architecture processes audio and documents into vector representations, allowing the system to retrieve relevant information more accurately and efficiently. Evaluations show that S2R significantly outperforms conventional cascade ASR models and approaches the quality of systems using perfect transcriptions, especially across diverse languages. To advance research‚Ä¶
1760351035769.2058	https://t.co/q9cYl1ahS1
1760351035769.0618	This is how Anthropic decides what to build next‚Äîand it's brilliant. Instead of endless spec documents and roadmap debates, the Claude Code team has cracked the code on feature prioritization: prototype first, decide later. Here's their process (shared by Catherine Wu, Product Lead at Anthropic): Step 1: Idea ‚Üí Prototype Got a feature idea? Skip the spec. Build a working prototype using Claude Code instead. Step 2: Internal Launch Ship that prototype to all Anthropic engineers immediately. No polish required‚Äîjust‚Ä¶
1760351035770.5107	Azure AI Foundry has announced the launch of several new OpenAI multimodal models‚ÄîGPT-image-1-mini, GPT-realtime-mini, and GPT-audio-mini‚Äîalongside major safety upgrades for GPT-5, empowering developers to create, experiment, and scale solutions using text, image, audio, and video. These models are designed for rapid, cost-effective deployment, offering real-time responsiveness, resource efficiency, and robust safety guardrails for sensitive conversations. The Microsoft Agent Framework (now in preview) further enables orchestration of multi-agent systems, enhancing the development of intelligent, scalable agentic solutions. The new offerings allow‚Ä¶
1760351035771.5396	üíª Introducing Gemini 2.5 Computer Use, available in preview via the API. It builds on Gemini 2.5 Pro‚Äôs vision &amp; reasoning capabilities to power agent interactions with UIs. It completes tasks with lower latency, &amp; outperforms alternatives on web &amp; mobile control benchmarks. https://t.co/K8buLl2gtL
1760351035771.4045	Figure 03 coming 10/9 https://t.co/LVHGzRmvh1
1760351035772.0903	Google DeepMind has introduced CodeMender, an advanced AI agent designed to automatically identify and fix critical software vulnerabilities. Leveraging state-of-the-art Gemini models and specialized tools for program analysis, debugging, and code validation, CodeMender can both reactively patch new vulnerabilities and proactively rewrite existing code to prevent future issues. Over six months, it has already contributed 72 security fixes to large open-source projects, demonstrating the ability to autonomously reason about code, validate changes, and self-correct as needed. The system uses techniques‚Ä¶
1760351035772.6252	Software vulnerabilities can be notoriously time-consuming for developers to find and fix. Today, we‚Äôre sharing details about CodeMender: our new AI agent that uses Gemini Deep Think to automatically patch critical software vulnerabilities. üßµ
1760351035773.6282	Codex is now GA, along with 3 features that make it more useful for engineering teams: - @Codex in Slack - Codex SDK - New admin tools
1760351035773.5442	üé• Sora 2 and Sora 2 Pro are now in the API. And new image and speech-to-speech models that are cheaper than their full-sized counterparts, but with similar quality: üì∏ gpt-image-1-mini (80% cheaper) üó£Ô∏è gpt-realtime-mini (70% cheaper) https://t.co/0jj63pzjc7
1760351035774.4019	OpenAI has introduced a new generation of apps within ChatGPT, along with a developer Apps SDK (available in preview) that enables the creation of interactive, conversational apps directly in the chat interface. These apps can be accessed when suggested by ChatGPT or invoked by name, blending natural language interactions with interactive elements like maps, playlists, and presentations. Initial launch partners include Booking.com, Canva, Coursera, Figma, Expedia, Spotify, and Zillow, with more partners and app integrations coming soon. Developers can build‚Ä¶
1760351035775.0193	OpenAI has introduced AgentKit, a suite of tools aimed at simplifying the building, deployment, and optimization of AI agents for developers and enterprises. AgentKit features Agent Builder‚Äîa visual interface for creating and versioning multi-agent workflows; Connector Registry‚Äîa central hub for managing data and tool connections; and ChatKit‚Äîa toolkit for embedding customizable chat-based agent experiences. The release also includes enhanced evaluation tools like datasets, trace grading, automated prompt optimization, and support for evaluating third-party models. Reinforcement fine-tuning (RFT) is now available‚Ä¶
1760351035775.6597	Two more ships: ‚ö°Ô∏èGPT-5 API requests are 40% faster on the priority processing tier compared to the standard tier. https://t.co/hcbA2uGufa üìàThe new service health dashboard lets you monitor uptime, request time, token velocity, and time to first token. https://t.co/URCF5aNtY4 https://t.co/1843MI85rp
1760351035776.0266	An application error has occurred, specifically a client-side exception. This error prevents the proper display or functioning of the intended content. The issue is likely related to problems within the user's browser, and further details can be found in the browser console. The main content is currently inaccessible due to this error.
1760351035777.4648	OpenAI's AgentKit launch shows the industry is still thinking in old paradigms. Visual builders and drag and drop canvases feel like we're recreating no-code tools from a decade ago. The real breakthrough will be a conversational agent that lets you describe what you want in natural language and it builds itself. No canvas, no nodes, no workflows. That's what I'm shipping this week, if you want early access hit me up!
1760351035777.196	Some thoughts on the RL LoRA discourse, I understand this argument to be: - RL: all tokens in a sample gets a single scalar reward so O(1) - SFT: Each token computes cross entropy independently so O(tokens) This makes sense in their setup but.... https://t.co/7IjtTbBKVv
1760351035778.5046	CEO's question: What will be the hourly cost of work of a humanoid robot? Several projections have been published, e.g. by @CernBasher, @adam_dorr and @GoingBallistic5. Here's my take. I've produced a long-form video on this question (see link in comments). Here is the essence - based on very conservative assumptions (see attached image). - Production cost: $30,000. A humanoid is ~5% the mass of a passenger car. The costly parts are actuators and gearboxes; the rest is electronics, sensors, a‚Ä¶
1760351035778.2969	This guide introduces the **evaluation flywheel**, a structured, iterative process for building resilient prompts in AI applications. The flywheel involves three phases: **Analyze** (identify failure modes through manual annotation and coding), **Measure** (quantify failures with test datasets and automated graders), and **Improve** (refine prompts and system components based on measured results). This cycle enables continuous prompt optimization, ensuring high-quality responses across a wide range of inputs and making AI systems more robust and reliable in production. The guide also covers‚Ä¶
1760351035779.5	I analyzed every single prompt in Anthropic's official library. What I found will make you delete every "prompt engineering course" you bought. Here's the framework they actually use:
1760351035780.7522	Recent research from Thinking Machines Lab demonstrates that LoRA (Low-Rank Adaptation) can achieve performance comparable to full fine-tuning while using only about 67% of the compute, provided it is configured correctly. The Hugging Face TRL documentation provides practical guidance and code examples for reproducing these results using both supervised fine-tuning (SFT) and reinforcement learning (GRPO) tasks. Key recommendations include applying LoRA to all linear weight matrices (not just attention layers), selecting an appropriate rank for the adapter (e.g., rank 256‚Ä¶
1760351035780.5833	Introducing AgentKit‚Äîbuild, deploy, and optimize agentic workflows. üí¨ ChatKit: Embeddable, customizable chat UI üë∑ Agent Builder: WYSIWYG workflow creator üõ§Ô∏è Guardrails: Safety screening for inputs/outputs ‚öñÔ∏è Evals: Datasets, trace grading, auto-prompt optimization https://t.co/pGgNHKOvj3
1760351035782.7793	The Apps SDK is OpenAI's framework for developers to build and test custom apps for ChatGPT, currently available in preview. The documentation covers key concepts such as setting up an MCP server, designing conversational user experiences, authenticating users, persisting state, and deploying apps. Developers are guided through planning use cases, defining tools and components, and accessing resources and references for integration. Quality and security are emphasized through app design guidelines and developer policy standards. Additional guides are available for optimizing‚Ä¶
1760351035783.1802	OpenAI DevDay pricing updates: Sora: - Sora 2 720p: 10 cents per second - Sora 2 Pro 720p: 30 cents per second - Sora 2 Pro 1080p: 50 cents per second GPT-5 Pro: - Input: $15.00 per million tokens - Output: $120 per million tokens - No caching discount :( https://t.co/lxMf9V762e
1760351035784.902	The main content provides an in-depth overview of the HNSW (Hierarchical Navigable Small World) index, which is the default vector index type in Weaviate. HNSW enables fast and accurate searches of high-dimensional vectors by organizing them in a multi-layer graph structure, balancing global traversal speed and local search accuracy. It is highly scalable and tunable, with key trade-offs between search speed, accuracy, and memory usage that can be adjusted via parameters such as the number of node connections, dynamic list‚Ä¶
1760351035785.9502	SkyRL tx is an open source project that implements a backend for the Tinker API, a REST-based interface for neural network inference and training announced by Thinking Machines. The Tinker API unifies forward and backward passes, enabling seamless inference, training, and online learning through a single interface, and leverages LoRA to facilitate efficient multi-tenancy and lower infrastructure costs. SkyRL tx allows users to deploy their own Tinker-like service on their hardware, supporting batching, multi-user LoRA adapters, and efficient model updates.‚Ä¶
1760351035786.9104	Simon Willison introduces the concept of **vibe engineering** as a counterpart to "vibe coding"‚Äîthe latter being a fast, prompt-driven, and often careless approach to using AI for software development. Vibe engineering, by contrast, refers to experienced professionals leveraging LLMs and coding agents to accelerate their work while maintaining high standards of accountability, code quality, and software engineering best practices. The article highlights how agentic coding tools like Claude Code, OpenAI Codex CLI, and Gemini CLI have made LLMs more useful‚Ä¶
1760354102479.755	The paper introduces ACE (Agentic Context Engineering), a framework designed to enhance large language model (LLM) applications by treating the model context as an evolving playbook. Instead of retraining model weights, ACE incrementally updates and organizes contextual strategies through generation, reflection, and curation processes. This approach addresses issues like brevity bias and context collapse, ensuring that detailed, domain-specific knowledge is preserved and scaled efficiently for long-context LLMs. Empirically, ACE significantly outperforms strong baselines on both agent-based and domain-specific reasoning tasks,‚Ä¶
